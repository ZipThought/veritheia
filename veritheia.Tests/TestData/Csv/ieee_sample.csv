"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"LLM-Driven SAT Impact on Phishing Defense: A Cross-Sectional Analysis","H. İŞ","Department of Computer Engineering, Batman University, Batman, Turkey","2024 12th International Symposium on Digital Forensics and Security (ISDFS)","15 May 2024","2024","","","1","5","Amidst the growing sophistication of phishing threats that exploit human vulnerabilities, this study investigates the effectiveness of Security Awareness Training (SAT) enhanced by Large Language Models (LLMs). Targeting a diverse group of 1,270 participants, including academicians, officers, and students, it aims to evaluate whether LLM-driven SAT can strengthen phishing defenses and cultivate a more resilient digital environment. Initial assessments revealed a baseline Phish Prone Percentage (PPP) of 18.3%, indicating a pronounced vulnerability across participant groups. The deployment of an LLM-enhanced SAT program, characterized by its adaptive and interactive training modules, led to a significant post-training reduction in PPP to 6.3%. This outcome demonstrates the program's success in mitigating phishing risks and underscores the necessity of evolving SAT strategies to combat the dynamic nature of phishing attacks. The study's findings, illustrating a substantial improvement in phishing defense capabilities through LLM-integrated SAT, advocate for the integration of advanced technologies in cybersecurity education. By effectively lowering phishing vulnerability from 18.3% to 6.3%, this research highlights the critical role of innovative training methodologies in enhancing digital security across varied academic and professional landscapes.","2768-1831","979-8-3503-3036-6","10.1109/ISDFS60797.2024.10527274","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10527274","Phishing;Large Language Model(LLM);Cyber Security;Security Awareness Training(SAT);Artificial Intelligence","Training;Phishing;Digital forensics;Organizations;Testing","","","","12","IEEE","15 May 2024","","","IEEE","IEEE Conferences"
"LLM-based Vulnerability Detection","H. Li; L. Shan","School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China","2023 International Conference on Human-Centered Cognitive Systems (HCCS)","1 Mar 2024","2023","","","1","4","The emerging Large language models (LLMs) are increasingly used as a revolutionised tools in many industry. In cyber security, the LLMs can offer innovative ways to detect, identify, and mitigate vulnerability through their natural language processing capability. This work aims to fine tune pre-trained LLMs to detect anomalies and vulnerability by analysing vast amounts of data. A ChatGPT 3.5 model based vulnerability detector were developed that can conduct common vulnerability analysis. Experimental results demonstrate the effectiveness of proposed solution.","","979-8-3503-5918-3","10.1109/HCCS59561.2023.10452613","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10452613","Cyber attack;Detection;LLM;GPT","Industries;Analytical models;Detectors;Chatbots;Cognitive systems;Cyberattack","","","","16","IEEE","1 Mar 2024","","","IEEE","IEEE Conferences"
"PrivacyAsst: Safeguarding User Privacy in Tool-Using Large Language Model Agents","X. Zhang; H. Xu; Z. Ba; Z. Wang; Y. Hong; J. Liu; Z. Qin; K. Ren","State Key Laboratory of Blockchain and Data Security, School of Cyber Science and Technology, College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China; State Key Laboratory of Blockchain and Data Security, School of Cyber Science and Technology, College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China; State Key Laboratory of Blockchain and Data Security, School of Cyber Science and Technology, College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China; State Key Laboratory of Blockchain and Data Security, School of Cyber Science and Technology, College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China; University of Connecticut, Stamford, CT, USA; State Key Laboratory of Blockchain and Data Security, School of Cyber Science and Technology, College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China; State Key Laboratory of Blockchain and Data Security, School of Cyber Science and Technology, College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China; State Key Laboratory of Blockchain and Data Security, School of Cyber Science and Technology, College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China","IEEE Transactions on Dependable and Secure Computing","","2024","PP","99","1","16","Swift advancements in large language model (LLM) technologies lead to widespread research and applications, particularly in integrating LLMs with auxiliary tools, known as tool-using LLM agents. However, amid user interactions, the transmission of private information to both LLMs and tools poses considerable privacy risks to users. In this paper, we delve into current privacy-preserving solutions for LLMs and outline three pivotal challenges for tool-using LLM agents: generalization to both open-source and closed-source LLMs and tools, compliance with privacy requirements, and applicability to unrestricted tasks. To tackle these challenges, we present PrivacyAsst, the first privacy-preserving framework tailored for tool-using LLM agents, encompassing two solutions for different application scenarios. First, we incorporate a homomorphic encryption scheme to ensure computational security guarantees for users as a safeguard against both open-source and closed-source LLMs and tools. Moreover, we propose a shuffling-based solution to broaden the framework's applicability to unrestricted tasks. This solution employs an attribute-based forgery generative model and an attribute shuffling mechanism to craft privacy-preserving requests, effectively concealing individual inputs. Additionally, we introduce an innovative privacy concept, $t$-closeness in image data, for privacy compliance within this solution. Finally, we implement PrivacyAsst, accompanied by two case studies, demonstrating its effectiveness in advancing privacy-preserving artificial intelligence.","1941-0018","","10.1109/TDSC.2024.3372777","National Key R&D Program of China(grant numbers:2023YFB2904000); National Natural Science Foundation of China(grant numbers:62172359,U20A20178,62072395); Zhejiang Provincial Natural Science Foundation of China(grant numbers:LD24F020010); Fundamental Research Funds for the Central Universities(grant numbers:2021FZZX001-27); Hangzhou Leading Innovation and Entrepreneurship Team(grant numbers:TD2020003); National Science Foundation(grant numbers:CNS-2308730); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10458329","Large language model (LLM);Tool-using LLM agent;Privacy;Homomorphic encryption; $ t$ -Closeness","Privacy;Task analysis;Image color analysis;Cryptography;Data privacy;Data models;Forgery","","","","","IEEE","5 Mar 2024","","","IEEE","IEEE Early Access Articles"
"LLM-based Attack Scenarios Generator with IT Asset Management and Vulnerability Information","T. Naito; R. Watanabe; T. Mitsunaga","INIAD, Toyo University, Tokyo, Japan; INIAD, Toyo University, Tokyo, Japan; INIAD, Toyo University The Tokyo Foundation for Policy Research, Tokyo, Japan","2023 6th International Conference on Signal Processing and Information Security (ICSPIS)","12 Dec 2023","2023","","","99","103","As businesses become more dependent on IT due to digital transformation, a variety of attackers are targeting companies, government agencies, and individuals to steal information and disrupt services. To reduce the risks these cyber threats pose, penetration testing and red teaming are important. On the other hand, these initiatives require skills and knowledge, and there is a shortage of human resources. This research aims to demonstrate the effectiveness of a system that inputs asset management data and vulnerability information into ChatGPT and searches for attack routes with a high threat level. Specifically, ChatGPT uses information used for IT asset management (OS type, version, device usage, account), vulnerability information published by CISA, and network information as input values to verify whether it is possible to output attack routes that are useful for penetration testing and red teaming. The results of the experiment confirmed that attack vectors for penetration testing and red teaming could be used to effectively uncover cybersecurity threats within an organization and perform risk assessments.","2831-3844","979-8-3503-2959-9","10.1109/ICSPIS60075.2023.10344019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10344019","ChatGPT;Cybersecurity;IT Asset Management;Attack Scenario","Digital transformation;Government;Information security;Companies;Signal processing;Chatbots;Asset management","","1","","18","IEEE","12 Dec 2023","","","IEEE","IEEE Conferences"
"Multilevel Fuzzy Logic-Based Approach for Critical Energy Infrastructure's Cyber Resilience Assessment","Y. Brezhniev","Department of Computer Systems, National Aerospace University ""KhAI"", Kharkiv, Ukraine","2019 10th International Conference on Dependable Systems, Services and Technologies (DESSERT)","25 Jul 2019","2019","","","213","217","This paper presents approach for critical energy infrastructure's (CEI) cyber resilience assessment. The CEI is the vital physical system of systems, whose accidents and failures lead to damage of economy, environment, impact on health and lives of people. The analysis of cyber incidents with Ukrainian CEI confirms the importance of the task of increasing its cyber resilience to external hostile influences and keeping of the appropriate level of functionality, safety and reliability. This paper is devoted to development of approach for CEI's cyber resilience assessment considering the important capacities of its systems (adaptivity, restoration, absorbability, preventive) and interdependencies between them. This approach is based on application of multilevel fuzzy logic models (called as logic-linguistic models, LLM) taking into consideration the data available from expert's knowledge. The comparison between risk management and resilience assurance is performed. The new risk-oriented definition of resiliency is suggested.","","978-1-7281-1733-1","10.1109/DESSERT.2019.8770034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8770034","critical energy infrastructure;cyber resilience;logic linguistic models;fuzzy logic;resilience capacities","Resilience;Risk management;Computer crime;Accidents;Safety;Linguistics","","","","12","IEEE","25 Jul 2019","","","IEEE","IEEE Conferences"
